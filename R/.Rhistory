help(tokens)
help(perplexity)
pacman::p_load(janitor, dplyr, caret, randomForest, stargazer, ldatuning,
topicmodels,
ggplot2,
rjson,
quanteda,
tidytext,
stringi,
tidyr,
lubridate,
parallel,
doParallel,
readr,
stringr,
stm,
quanteda.textmodels,
lsa,
text2vec)
help("perplexity")
help(LDA)
dim(test2a)
dim(test2b)
test2b_flat <- Matrix::colSums(test2b)
test2b_flat <- as.matrix(test2b_flat)
dim(test2b_flat)
dim(test2a)
test2b_flat <- t(as.matrix(test2b_flat))
test2b_flat <- Matrix::colSums(test2b)
test2b_flat <- t(as.matrix(test2b_flat))
dim(test2b_flat)
as.matrix(test2a)
test2a_mat <- as.matrix(test2a@x)
View(test2a_mat)
View(test2b_flat)
test2b_flat <- Matrix::colSums(test2b)
test2b_flat <- t(as.matrix(test2b_flat))
test2b_flat <- Matrix::colSums(test2b)
test2b_flat <- as.matrix(test2b_flat)
View(test2b_flat)
View(test2a)
View(test2a_mat)
all.equal(as.numeric(test2a_mat), as.numeric(test2b_flat))
help(tokens)
rm(list = ls())
dat <- readRDS("/Users/christianbaehr/Documents/GitHub/POL504_precept_2023/data/news_data.rds")
test1 <- term_matrix(text)
test1 <- term_matrix(dat$headline)
test2.tok <- tokens(dat$headline)
test2a <- dfm(test2.tok)
dim(test1)
dim(test2a)
stylest1terms <- colnames(test1)
stylest2aterms <- colnames(test2a)
stylest1terms[!stylest1terms %in% stylest2aterms]
stylest2aterms[!stylest2aterms %in% stylest1terms]
unique(stylest1terms[!stylest1terms %in% stylest2aterms])
unique(stylest2aterms[!stylest2aterms %in% stylest1terms])
test2b.tok <- tokens(dat$headline, split_hyphens = T)
test2b <- dfm(test2b.tok)
dim(test1)
dim(test2a)
dim(test2b)
stylest1terms <- colnames(test1)
stylest2aterms <- colnames(test2a)
stylest2bterms <- colnames(test2b)
unique(stylest1terms[!stylest1terms %in% stylest2aterms])
unique(stylest2aterms[!stylest2aterms %in% stylest1terms])
unique(stylest1terms[!stylest1terms %in% stylest2aterms])
unique(stylest1terms[!stylest1terms %in% stylest2bterms])
unique(stylest1terms[!stylest1terms %in% stylest2aterms])
temp <- "ahmadinejad's"
temp <- "ahmadinejad's"
term_matrix(temp)
dfm(tokens(temp))
unique(stylest2aterms[!stylest2aterms %in% stylest1terms])
sort(unique(stylest1terms[!stylest1terms %in% stylest2aterms]))
sort(unique(stylest2aterms[!stylest2aterms %in% stylest1terms]))
temp <- "ahmadinejad’s"
term_matrix(temp)
dfm(tokens(temp))
c("’", "'")
temp <- c("’", "'")
term_matrix(temp)
dfm(tokens(temp))
dat$headline <- gsub("’", "'", dat$headline)
test1 <- term_matrix(dat$headline)
test2.tok <- tokens(dat$headline)
test2a <- dfm(test2.tok)
test2b.tok <- tokens(dat$headline, split_hyphens = T)
test2b <- dfm(test2b.tok)
dim(test1)
dim(test2a)
dim(test2b)
stylest1terms <- colnames(test1)
stylest2aterms <- colnames(test2a)
stylest2bterms <- colnames(test2b)
sort(unique(stylest1terms[!stylest1terms %in% stylest2aterms]))
sort(unique(stylest1terms[!stylest1terms %in% stylest2bterms]))
sort(unique(stylest1terms[!stylest1terms %in% stylest2aterms]))
sort(unique(stylest2aterms[!stylest2aterms %in% stylest1terms]))
temp <- c("--", "-")
term_matrix(temp)
dfm(tokens(temp))
dat$headline <- gsub("--", "-", dat$headline)
test1 <- term_matrix(dat$headline)
test2.tok <- tokens(dat$headline)
test2a <- dfm(test2.tok)
test2b.tok <- tokens(dat$headline, split_hyphens = T)
test2b <- dfm(test2b.tok)
dim(test1)
dim(test2a)
dim(test2b)
stylest1terms <- colnames(test1)
stylest2aterms <- colnames(test2a)
stylest2bterms <- colnames(test2b)
sort(unique(stylest1terms[!stylest1terms %in% stylest2aterms]))
#sort(unique(stylest1terms[!stylest1terms %in% stylest2bterms]))
sort(unique(stylest2aterms[!stylest2aterms %in% stylest1terms]))
temp <- c("#14-1508")
term_matrix(temp)
dfm(tokens(temp))
temp <- c("#hello")
term_matrix(temp)
dfm(tokens(temp))
dat$headline <- gsub("#", "", dat$headline)
test1 <- term_matrix(dat$headline)
test2.tok <- tokens(dat$headline)
test2a <- dfm(test2.tok)
test2b.tok <- tokens(dat$headline, split_hyphens = T)
test2b <- dfm(test2b.tok)
dim(test1)
dim(test2a)
dim(test2b)
stylest1terms <- colnames(test1)
stylest2aterms <- colnames(test2a)
stylest2bterms <- colnames(test2b)
sort(unique(stylest1terms[!stylest1terms %in% stylest2aterms]))
#sort(unique(stylest1terms[!stylest1terms %in% stylest2bterms]))
sort(unique(stylest2aterms[!stylest2aterms %in% stylest1terms]))
#sort(unique(stylest2bterms[!stylest2bterms %in% stylest1terms]))
temp <- c("wars'-meets-shakespeare")
term_matrix(temp)
dfm(tokens(temp))
temp <- c("-meets-shakespeare")
term_matrix(temp)
dfm(tokens(temp))
## looks like term_matrix() splits on the "'" character. Also separates "-"
## from any text that follows
temp <- c("wars'meets-shakespeare")
term_matrix(temp)
dfm(tokens(temp))
## looks like term_matrix() splits on the "'" character. Also separates "-"
## from any text that follows
temp <- c("wars'-meets-shakespeare")
term_matrix(temp)
dfm(tokens(temp))
temp <- c("wars-meets-shakespeare")
term_matrix(temp)
dfm(tokens(temp))
temp <- c("wars'-meets-shakespeare")
term_matrix(temp)
dfm(tokens(temp))
temp <- c("wars'meets-shakespeare")
term_matrix(temp)
dfm(tokens(temp))
temp <- c("-meets-shakespeare")
term_matrix(temp)
dfm(tokens(temp))
## also breaks the hyphen away from the subsequent text when it is a leading hyphen
temp <- c("-meets-shakespeare")
term_matrix(temp)
dfm(tokens(temp))
temp <- c("'-meets-shakespeare")
term_matrix(temp)
dfm(tokens(temp))
temp <- c("wars'")
term_matrix(temp)
dfm(tokens(temp))
library(quanteda)
library(corpus)
load("novels_excerpts.RData")
## both quanteda and corpus will separate text from trailing hyphens
temp <- c("wars'")
term_matrix(temp)
dfm(tokens(temp))
temp="ever-growing"
corpus::term_matrix(temp)
library(quanteda)
dfm(tokens(temp))
temp="Christian's"
corpus::term_matrix(temp)
dfm(tokens(temp))
line <- "I went to the store --but forgot my wallet"
as.matrix(corpus::term_matrix(line))
as.matrix(quanteda::dfm(tokens(line)))
as.matrix(quanteda::dfm(tokens(line, split_hyphens = T)))
dat=read.csv("/Users/christianbaehr/Desktop/scrape_municipality_catcherrors/muni_data_Allegheny_1.csv", sep = ";")
View(dat)
t<- 1
length(t)
class(t)
is.integer(t)
t<- 1.5
as.integer(t)
t && 1
t %% 1
getwd()
load("/Users/christianbaehr/Documents/GitHub/stylest2_project/stylest2_project/data/novels_excerpts.RData")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
data(novels)
setwd("/Users/christianbaehr/Documents/GitHub/stylest2_project/stylest2_project/data")
data(novels_excerpts)
# show a snippet of the data
kable(novels[c(1,4,8), ]) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
library(stylest2)
library(quanteda)
# show a snippet of the data
kable(novels[c(1,4,8), ]) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
library(kableExtra)
# show a snippet of the data
kable(novels[c(1,4,8), ]) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
unique(novels$author)
novels_tok <- tokens(novels)
novels_tok <- tokens(novels$text)
docvars(novels_tok)["author"] <- novels$author
novels_dfm <- dfm(novels_tok)
docvars(novels_dfm)
novels_tok <- tokens(novels$text)
novels_dfm <- dfm(novels_tok)
unique(novels$author)
docvars(novels_dfm)["author"] <- novels$author
help(tokens)
novels_tok <- tokens(novels$text,
remove_punct = T,
remove_symbols = T,
remove_numbers = T,
remove_separators = T,
split_hyphens = T)
novels_dfm <- dfm(novels_tok)
vocab_with_defaults <- stylest2_select_vocab(dfm = novels_dfm)
source("../R/stylest2_select_vocab.R")
vocab_with_defaults <- stylest2_select_vocab(dfm = novels_dfm)
source("../R/stylest2_select_vocab.R")
vocab_with_defaults <- stylest2_select_vocab(dfm = novels_dfm)
novels_tok <- tokens(novels$text,
remove_punct = T,
remove_symbols = T,
remove_numbers = T,
remove_separators = T,
split_hyphens = T)
novels_dfm <- dfm(novels_tok)
unique(novels$author)
docvars(novels_dfm)["author"] <- novels$author
set.seed(1234)
vocab_with_defaults <- stylest2_select_vocab(dfm = novels_dfm)
source("../R/stylest2_fit.R")
vocab_with_defaults <- stylest2_select_vocab(dfm = novels_dfm)
source("../R/stylest2_predict.R")
vocab_with_defaults <- stylest2_select_vocab(dfm = novels_dfm)
vocab_with_defaults <- stylest2_select_vocab(dfm = novels_dfm)
help(warning)
suppressWarnings()
help("suppressWarnings")
suppressWarnings(warning("oopsy"))
warning("oopsy")
warn <- warning("Detected multiple texts with the same author. Collapsing to author-level dfm for stylest2_fit() function.")
warn
setwd("/Users/christianbaehr/Documents/GitHub/stylest2/R/")
library(stylest)
library(quanteda)
library(quanteda.corpora)
source("stylest2_select_vocab.R")
source("stylest2_fit.R")
source("stylest2_predict.R")
load("../data/novels_excerpts.RData")
novels$id <- 1:nrow(novels)
novelst <- tokens(novels$text)
novelsd <- dfm(novelst)
docvars(novelsd)["author"] <- novels$author
## fit stylest model over all SOTU observations.
s1_fit <- stylest_fit(x = novels$text,
speaker = novels$author)
setwd("/Users/christianbaehr/Documents/GitHub/stylest2/R/")
library(stylest)
library(quanteda)
library(quanteda.corpora)
source("stylest2_select_vocab.R")
source("stylest2_fit.R")
source("stylest2_predict.R")
## load State of the Union speeches
## this is a corpus object with speech text a docvar for President name
load("../data/sotu_speeches.RData")
## convert corpus object to quanteda dfm
## Note: we do not include any pre-processing options. This is with the purpose
## to evaluate the natural performance of stylest2 relative to stylest on an
## example dataset
sotu_dfm <- dfm(tokens(sotu))
## load State of the Union speeches
## this is a corpus object with speech text a docvar for President name
load("../data/sotu_speeches.RData")
setwd("/Users/christianbaehr/Documents/GitHub/stylest2_project/R/")
setwd("/Users/christianbaehr/Documents/GitHub/stylest2_project/stylest2_project/R/")
library(stylest)
library(quanteda)
library(quanteda.corpora)
source("stylest2_select_vocab.R")
source("stylest2_fit.R")
source("stylest2_predict.R")
## load State of the Union speeches
## this is a corpus object with speech text a docvar for President name
load("../data/sotu_speeches.RData")
setwd("/Users/christianbaehr/Documents/GitHub/stylest2/R/")
library(stylest)
library(quanteda)
library(quanteda.corpora)
source("stylest2_select_vocab.R")
source("stylest2_fit.R")
source("stylest2_predict.R")
## load State of the Union speeches
## this is a corpus object with speech text a docvar for President name
load("../data/sotu_speeches.RData")
rm(list = ls())
setwd("/Users/christianbaehr/Documents/GitHub/stylest2/R/")
library(stylest)
library(quanteda)
library(quanteda.corpora)
source("stylest2_select_vocab.R")
source("stylest2_fit.R")
source("stylest2_predict.R")
## load State of the Union speeches
## this is a corpus object with speech text a docvar for President name
load("../data/sotu_speeches.RData")
## convert corpus object to quanteda dfm
## Note: we do not include any pre-processing options. This is with the purpose
## to evaluate the natural performance of stylest2 relative to stylest on an
## example dataset
sotu_dfm <- dfm(tokens(sotu))
## set authorship docvar name to "author"
docvars(sotu_dfm)["author"] <- docvars(sotu)["President"][[1]]
############################# stylest2_select_vocab #############################
## generate a random seed. Used by stylest2_select_vocab() to bin data into
## random "folds" to perform k-fold cross-validation.
num <- sample(1:1000, 1)
set.seed(num)
s1_terms <- stylest_select_vocab(x=as.character(sotu), speaker = docvars(sotu)["President"][[1]])
s1_terms$miss_pct
## miss rate in test fold, across cutoff hyperparameter values
set.seed(num)
s2_terms <- stylest2_select_vocab(dfm=sotu_dfm)
s2_terms$cv_missrate_results
warnings()
s2_terms_nowarn <- suppressWarnings(stylest2_select_vocab(dfm=sotu_dfm))
s2_terms_nowarn==s2_terms
all.equal(s2_terms_nowarn, s2_terms)
num <- sample(1:1000, 1)
set.seed(num)
s2_terms <- stylest2_select_vocab(dfm=sotu_dfm)
set.seed(num)
s2_terms_nowarn <- suppressWarnings(stylest2_select_vocab(dfm=sotu_dfm))
all.equal(s2_terms_nowarn, s2_terms)
rm(list = ls())
source("/Users/christianbaehr/Documents/GitHub/stylest2_project/stylest2_project/R/stylest2_fit.R")
source("/Users/christianbaehr/Documents/GitHub/stylest2_project/stylest2_project/R/stylest2_predict.R")
source("/Users/christianbaehr/Documents/GitHub/stylest2_project/stylest2_project/R/stylest2_select_vocab.R")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(kableExtra)
library(stylest2)
library(stylest2)
library(quanteda)
data(novels)
source("/Users/christianbaehr/Documents/GitHub/stylest2_project/stylest2_project/data/novels_excerpts.RData")
load("/Users/christianbaehr/Documents/GitHub/stylest2_project/stylest2_project/data/novels_excerpts.RData")
# show a snippet of the data
kable(novels[c(1,4,8), ]) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
novels_tok <- tokens(novels$text)
novels_dfm <- dfm(novels_tok)
unique(novels$author)
docvars(novels_dfm)["author"] <- novels$author
novels_tok <- tokens(novels$text,
remove_punct = T,
remove_symbols = T,
remove_numbers = T,
remove_separators = T,
split_hyphens = T)
novels_dfm <- dfm(novels_tok)
unique(novels$author)
docvars(novels_dfm)["author"] <- novels$author
set.seed(1234)
vocab_with_defaults <- stylest2_select_vocab(dfm = novels_dfm)
vocab_with_defaults$cutoff_pct_best
vocab_with_defaults$miss_pct
vocab_with_defaults$cv_missrate_results
vocab_with_defaults$cutoff_pcts
vocab_with_defaults$cutoff_candidates
# Number of folds
vocab_with_defaults$nfold
# Percentile with best prediction rate
vocab_with_defaults$cutoff_pct_best
# Rate of INCORRECTLY predicted speakers of held-out texts
vocab_with_defaults$cv_missrate_results
# Data on the setup:
# Percentiles tested
vocab_with_defaults$cutoff_candidates
# Number of folds
vocab_with_defaults$nfold
terms_90 <- stylest_terms(dfm = novels_dfm, cutoff = 90)
terms_90 <- stylest2_terms(dfm = novels_dfm, cutoff = 90)
source("/Users/christianbaehr/Documents/GitHub/stylest2_project/stylest2_project/R/stylest2_select_vocab.R")
terms_90 <- stylest2_terms(dfm = novels_dfm, cutoff = 90)
terms_90
mod <- stylest2_fit(dfm = novels_dfm, terms = terms_90)
term_weights <- data.frame("word" = c("the", "and", "Floccinaucinihilipilification"),
"mean_distance" = c(0.1,0.2,0.001))
term_weights
mod <- stylest_fit(dfm = novels_dfm,
terms = terms_90,
term_weights = term_weights,
weight_varname = "mean_distance")
mod <- stylest2_fit(dfm = novels_dfm,  terms = terms_90, term_weights = term_weights, weight_varname = "mean_distance")
mod <- stylest2_fit(dfm = novels_dfm,  terms = terms_90, term_weights = term_weights)
mod <- stylest2_fit(dfm = novels_dfm,  terms = terms_90, term_weights = term_weights)
posterior <- stylest2_predict(dfm = novels_dfm, model = mod)
posterior <- stylest2_predict(dfm = novels_dfm, model = mod)
mod$term_weights
posterior <- stylest2_predict(dfm = novels_dfm, model = mod)
dfm=novels_dfm
model=mod
dfm_class <- class(dfm)
if ( dfm_class != 'dfm' | attr(dfm_class, 'package') != 'quanteda' ) {
stop('`dfm` must be a quanteda "dfm" object.')
}
if( attr(model, 'package') != 'stylest2' ) {
stop('`model` must be a "stylest2" model, fit using "stylest2_fit()".')
}
pred_docs_dfm <- quanteda::dfm_match(dfm, features=colnames(model$rate))
pred_docs_ntoken <- Matrix::rowSums(pred_docs_dfm)
speakers <- rownames(model$rate)
nspeaker <- length(unique(speakers))
if (is.null(prior)) {
log_prior <- rep(-log(nspeaker), nspeaker) # log(1/nspeaker)
} else {
log_prior <- log(prior)
}
prior=NULL
if (is.null(prior)) {
log_prior <- rep(-log(nspeaker), nspeaker) # log(1/nspeaker)
} else {
log_prior <- log(prior)
}
if (is.null(prior)) {
log_prior <- rep(-log(nspeaker), nspeaker) # log(1/nspeaker)
} else {
log_prior <- log(prior)
}
## we take the log of the speaker-specific rate for each term in the model,
## because it simplifies computation of the likelihood function
eta_tv <- log(model$rate)
eta_store <- eta_tv # store old etas for term_influence
if (!is.null(model$term_weights)) {
# make sure weights are in the same order for matrix multiplication
sorted_weights <- model$term_weights[colnames(eta_tv)]
for (i in 1:nrow(eta_tv)) {
eta_tv[i, ] <- eta_tv[i, ] * sorted_weights
}
}
model$term_weights
!is.null(model$term_weights)
colnames(eta_tv)
model$term_weights[colnames(eta_tv)]
model$term_weights
model$term_weights
colnames(eta_tv)
rownames(model$term_weights)
model$terms
colnames(eta_tv)
match(model$terms, colnames(eta_tv))
test <- c("upon", "is", "know")
match(model$terms, test)
match(test, model$terms)
model$term_weights[match(colnames(eta_tv), models$terms)]
match(colnames(eta_tv), model$terms)
match(colnames(eta_tv), model$terms)
match(test, model$terms)
source("/Users/christianbaehr/Documents/GitHub/stylest2_project/stylest2_project/R/stylest2_predict.R")
posterior <- stylest2_predict(dfm = novels_dfm, model = mod)
rm(list = ls())
source("/Users/christianbaehr/Documents/GitHub/stylest2_project/stylest2_project/R/stylest2_predict.R")
source("/Users/christianbaehr/Documents/GitHub/stylest2_project/stylest2_project/R/stylest2_fit.R")
source("/Users/christianbaehr/Documents/GitHub/stylest2_project/stylest2_project/R/stylest2_select_vocab.R")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(kableExtra)
#library(stylest2)
library(quanteda)
data(novels)
# show a snippet of the data
kable(novels[c(1,4,8), ]) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
novels <- load("/Use")
