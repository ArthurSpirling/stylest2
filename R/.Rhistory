counties
counties <- gsub('option>', "", counties)
counties
gsub('"', '', counties)
gsub('"|<', '', counties)
gsub('"|<|>', '', counties)
gsub('"|<|>|\\d', '', counties)
gsub('"|<|>|\\d|//', '', counties)
gsub('"|<|>|\\d|////', '', counties)
gsub('"|<|>|\\d|///', '', counties)
gsub('"|<|>|\\d|', '', counties)
counties <- gsub('"|<|>|\\d|', '', counties)
counties
counties <- gsub('////', '', counties)
counties
gsub('////', '', counties)
counties <- gsub("([\\])","", counties)
counties
counties <- readLines("/Users/christianbaehr/Desktop/counties.txt")
counties <- gsub("\t", "", counties)
counties <- gsub('option|value|select', "", counties)
counties <- gsub('"|<|>|\\d|=', '', counties)
counties
gsub("([/])","", counties)
gsub("/","", counties)
counties <- trimws(gsub("/","", counties))
counties
counties <- readLines("/Users/christianbaehr/Desktop/counties.txt")
counties <- gsub("\t", "", counties)
counties <- gsub('option|value|select|eded', "", counties)
counties <- gsub('"|<|>|\\d|=', '', counties)
counties <- trimws(gsub("/","", counties))
counties
counties <- readLines("/Users/christianbaehr/Desktop/counties.txt")
counties <- gsub("\t", "", counties)
counties <- gsub('option|value|select|eded', "", counties)
counties <- gsub('"|<|>|\\d|=', '', counties)
counties <- trimws(gsub("/","", counties))
counties
counties <- readLines("/Users/christianbaehr/Desktop/counties.txt")
counties <- gsub("\t", "", counties)
counties
counties <- readLines("/Users/christianbaehr/Desktop/counties.txt")
counties <- gsub("\t", "", counties)
counties <- gsub('option|value|selected', "", counties)
counties <- gsub('"|<|>|\\d|=', '', counties)
counties <- trimws(gsub("/","", counties))
counties
write.table(counties, "/Users/christianbaehr/Desktop/county_names.txt", row.names = F)
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
pacman::p_load(quanteda, quanteda.corpora, quanteda.textstats, dplyr, ggplot2, stringr)
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
pacman::p_load(quanteda, quanteda.corpora, quanteda.textstats, dplyr, ggplot2, stringr, sotu)
# merge the meta and text dataframes from the sotu package
sotu <- cbind(sotu_meta, sotu_text)
View(sotu)
sotu <- corpus(sotu, text_field = "sotu.text")
View(sotu)
sotu <- corpus(sotu, text_field = "sotu_text")
# merge the meta and text dataframes from the sotu package
sotu <- cbind(sotu_meta, sotu_text)
sotu <- sotu[which(sotu$year %in% 2007:2010), ]
sotu <- corpus(sotu, text_field = "sotu_text")
sotu.corpus <- corpus(sotu, text_field = "sotu_text")
sotu.tokens <- tokens(sotu.corpus)
library(quanteda.corpora)
ukmnfs <- data_corpus_ukmanifestos
test <- corpus_reshape(ukmnfs, to = "sentences")
library(quanteda)
library(quanteda.corpora)
ukmnfs <- data_corpus_ukmanifestos
test <- corpus_reshape(ukmnfs, to = "sentences")
test.colloc_6b <- textstat_collocations(test) %>% filter(collocation == "united kingdom")
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
pacman::p_load(quanteda, quanteda.corpora, quanteda.textstats, dplyr, ggplot2,
readtext, stringr, sotu, gutenbergr, stylest, text.alignment)
test.colloc_6b <- textstat_collocations(test) %>% filter(collocation == "united kingdom")
library(quanteda.corpora)
ukmnfs <- data_corpus_ukmanifestos
test <- corpus_reshape(ukmnfs, to = "sentences")
test.colloc_6b <- textstat_collocations(test) %>% filter(collocation == "united kingdom")
test.colloc_6b
test.colloc_6c <- textstat_collocations(test,  min_count=5)
##Lambda
test.colloc_6c_top10_lam <- test.colloc_6c %>% arrange(desc(lambda)) %>% top_n(10)
a <- read.table("/Users/christianbaehr/Downloads/scale_data/scaledata/Dennis+Schwartz/id.Dennis+Schwartz")
View(a)
a <- read.table("/Users/christianbaehr/Downloads/scale_data/scaledata/Dennis+Schwartz/id.Dennis+Schwartz")
b <- read.table("/Users/christianbaehr/Downloads/scale_data/scaledata/Dennis+Schwartz/rating.Dennis+Schwartz")
c <- read.table("/Users/christianbaehr/Downloads/scale_data/scaledata/Dennis+Schwartz/subj.Dennis+Schwartz")
c <- read.table("/Users/christianbaehr/Downloads/scale_data/scaledata/Dennis+Schwartz/subj.Dennis+Schwartz")
help("read.table")
c <- scan("/Users/christianbaehr/Downloads/scale_data/scaledata/Dennis+Schwartz/subj.Dennis+Schwartz")
c <- read.table("/Users/christianbaehr/Downloads/scale_data/scaledata/Dennis+Schwartz/subj.Dennis+Schwartz", sep = "\n")
View(c)
View(c)
a <- read.table("/Users/christianbaehr/Downloads/scale_data/scaledata/James+Berardinelli/id.James+Berardinelli")
b <- read.table("/Users/christianbaehr/Downloads/scale_data/scaledata/Dennis+Schwartz/rating.James+Berardinelli")
b <- read.table("/Users/christianbaehr/Downloads/scale_data/scaledata/James+Berardinelli/rating.James+Berardinelli")
c <- read.table("/Users/christianbaehr/Downloads/scale_data/scaledata/James+Berardinelli/subj.James+Berardinelli", sep = "\n")
c <- read.table("/Users/christianbaehr/Downloads/scale_data/scaledata/James+Berardinelli/subj.James+Berardinelli", sep = "\n", quote = "")
View(c)
reviews <- cbind(a, b, c)
View(reviews)
reviews <- cbind(a, b, c) |>
setNames(c("id", "rating", "text"))
b <- read.table("/Users/christianbaehr/Downloads/scale_data/scaledata/James+Berardinelli/label.4class.James+Berardinelli")
c <- read.table("/Users/christianbaehr/Downloads/scale_data/scaledata/James+Berardinelli/subj.James+Berardinelli", sep = "\n", quote = "")
reviews <- cbind(a, b, c) |>
setNames(c("id", "rating", "text"))
View(reviews)
table(reviews$rating)
root <- "/Users/christianbaehr/Downloads/scale_data/scaledata/%s/id.%s"
sprintf(root, "James+Berardinelli")
sprintf(root, c("James+Berardinelli", "James+Berardinelli"))
help(sprintf)
sprintf(root, "James+Berardinelli", "James+Berardinelli")
join <- function(name, class) {
a <- read.table(root, class, name, name)
b <- read.table(root, class, name, name)
c <- read.table(root, class, name, name)
reviews <- cbind(a, b, c) |>
setNames(c("id", "rating", "text"))
return(reviews)
}
names <- c("James+Berardinelli")
root <- "/Users/christianbaehr/Downloads/scale_data/scaledata/%s/%s.%s"
join <- function(name) {
a <- read.table(root, name, "id", name)
b <- read.table(root, name, "label", name)
c <- read.table(root, name, "subj", name)
reviews <- cbind(a, b, c) |>
setNames(c("id", "rating", "text"))
return(reviews)
}
names <- c("James+Berardinelli")
lapply(names, join)
root <- "/Users/christianbaehr/Downloads/scale_data/scaledata/%s/%s.%s"
join <- function(name) {
a <- read.table(sprintf(root, name, "id", name))
b <- read.table(sprintf(root, name, "label", name))
c <- read.table(sprintf(root, name, "subj", name))
reviews <- cbind(a, b, c) |>
setNames(c("id", "rating", "text"))
return(reviews)
}
names <- c("James+Berardinelli")
lapply(names, join)
root <- "/Users/christianbaehr/Downloads/scale_data/scaledata/%s/%s.%s"
join <- function(name) {
a <- read.table(sprintf(root, name, "id", name))
b <- read.table(sprintf(root, name, "label.4class", name))
c <- read.table(sprintf(root, name, "subj", name))
reviews <- cbind(a, b, c) |>
setNames(c("id", "rating", "text"))
return(reviews)
}
names <- c("James+Berardinelli")
lapply(names, join)
root <- "/Users/christianbaehr/Downloads/scale_data/scaledata/%s/%s.%s"
join <- function(name) {
a <- read.table(sprintf(root, name, "id", name))
b <- read.table(sprintf(root, name, "label.4class", name))
c <- read.table(sprintf(root, name, "subj", name), sep = "\n", quote = "")
reviews <- cbind(a, b, c) |>
setNames(c("id", "rating", "text"))
return(reviews)
}
names <- c("James+Berardinelli")
lapply(names, join)
root <- "/Users/christianbaehr/Downloads/scale_data/scaledata/%s/%s.%s"
join <- function(name) {
a <- read.table(sprintf(root, name, "id", name))
b <- read.table(sprintf(root, name, "label.4class", name))
c <- read.table(sprintf(root, name, "subj", name), sep = "\n", quote = "")
reviews <- cbind(a, b, c) |>
setNames(c("id", "rating", "text"))
return(reviews)
}
names <- c("James+Berardinelli", "Dennis+Schwartz", "Scott+Renshaw", "Steve+Rhodes")
out <- lapply(names, join)
out <- do.call(rbind, out)
View(out)
table(out$rating)
write.csv(out, "/Users/christianbaehr/Desktop/movie_reviews.csv", row.names = F)
## load packages
pacman::p_load(quanteda, quanteda.corpora, readtext, quanteda.textmodels,
quanteda.textplots, dplyr)
remotes::install_github("leeper/pdfcount")
1
library(quanteda)
library(corpus)
dat <- readRDS("/Users/christianbaehr/Documents/GitHub/POL504_precept_2023/data/news_data.rds")
test2.tok <- tokens(dat$headline)
text <- paste(dat$headline, collapse = " ")
text
paste(dat$headline[1:2], collapse = " ")
dat <- readRDS("/Users/christianbaehr/Documents/GitHub/POL504_precept_2023/data/news_data.rds")
text <- paste(dat$headline, collapse = " ")
test1 <- term_matrix(text)
test2.tok <- tokens(text)
test2 <- dfm(test2.tok)
test2.tok <- corpus_reshape(text, to="sentences")
test2.tok <- corpus_reshape(corpus(text), to="sentences")
test2.tok <- tokens(test2.tok)
test2 <- dfm(test2.tok)
test2.tok <- tokens(text)
test2a <- dfm(test2.tok)
test2.tok <- corpus_reshape(corpus(text), to="sentences")
test2.tok <- tokens(test2.tok)
test2b <- dfm(test2.tok)
library(conText)
conlabMan
conlabMan
help(tokens)
help(perplexity)
pacman::p_load(janitor, dplyr, caret, randomForest, stargazer, ldatuning,
topicmodels,
ggplot2,
rjson,
quanteda,
tidytext,
stringi,
tidyr,
lubridate,
parallel,
doParallel,
readr,
stringr,
stm,
quanteda.textmodels,
lsa,
text2vec)
help("perplexity")
help(LDA)
dim(test2a)
dim(test2b)
test2b_flat <- Matrix::colSums(test2b)
test2b_flat <- as.matrix(test2b_flat)
dim(test2b_flat)
dim(test2a)
test2b_flat <- t(as.matrix(test2b_flat))
test2b_flat <- Matrix::colSums(test2b)
test2b_flat <- t(as.matrix(test2b_flat))
dim(test2b_flat)
as.matrix(test2a)
test2a_mat <- as.matrix(test2a@x)
View(test2a_mat)
View(test2b_flat)
test2b_flat <- Matrix::colSums(test2b)
test2b_flat <- t(as.matrix(test2b_flat))
test2b_flat <- Matrix::colSums(test2b)
test2b_flat <- as.matrix(test2b_flat)
View(test2b_flat)
View(test2a)
View(test2a_mat)
all.equal(as.numeric(test2a_mat), as.numeric(test2b_flat))
help(tokens)
rm(list = ls())
dat <- readRDS("/Users/christianbaehr/Documents/GitHub/POL504_precept_2023/data/news_data.rds")
test1 <- term_matrix(text)
test1 <- term_matrix(dat$headline)
test2.tok <- tokens(dat$headline)
test2a <- dfm(test2.tok)
dim(test1)
dim(test2a)
stylest1terms <- colnames(test1)
stylest2aterms <- colnames(test2a)
stylest1terms[!stylest1terms %in% stylest2aterms]
stylest2aterms[!stylest2aterms %in% stylest1terms]
unique(stylest1terms[!stylest1terms %in% stylest2aterms])
unique(stylest2aterms[!stylest2aterms %in% stylest1terms])
test2b.tok <- tokens(dat$headline, split_hyphens = T)
test2b <- dfm(test2b.tok)
dim(test1)
dim(test2a)
dim(test2b)
stylest1terms <- colnames(test1)
stylest2aterms <- colnames(test2a)
stylest2bterms <- colnames(test2b)
unique(stylest1terms[!stylest1terms %in% stylest2aterms])
unique(stylest2aterms[!stylest2aterms %in% stylest1terms])
unique(stylest1terms[!stylest1terms %in% stylest2aterms])
unique(stylest1terms[!stylest1terms %in% stylest2bterms])
unique(stylest1terms[!stylest1terms %in% stylest2aterms])
temp <- "ahmadinejad's"
temp <- "ahmadinejad's"
term_matrix(temp)
dfm(tokens(temp))
unique(stylest2aterms[!stylest2aterms %in% stylest1terms])
sort(unique(stylest1terms[!stylest1terms %in% stylest2aterms]))
sort(unique(stylest2aterms[!stylest2aterms %in% stylest1terms]))
temp <- "ahmadinejad’s"
term_matrix(temp)
dfm(tokens(temp))
c("’", "'")
temp <- c("’", "'")
term_matrix(temp)
dfm(tokens(temp))
dat$headline <- gsub("’", "'", dat$headline)
test1 <- term_matrix(dat$headline)
test2.tok <- tokens(dat$headline)
test2a <- dfm(test2.tok)
test2b.tok <- tokens(dat$headline, split_hyphens = T)
test2b <- dfm(test2b.tok)
dim(test1)
dim(test2a)
dim(test2b)
stylest1terms <- colnames(test1)
stylest2aterms <- colnames(test2a)
stylest2bterms <- colnames(test2b)
sort(unique(stylest1terms[!stylest1terms %in% stylest2aterms]))
sort(unique(stylest1terms[!stylest1terms %in% stylest2bterms]))
sort(unique(stylest1terms[!stylest1terms %in% stylest2aterms]))
sort(unique(stylest2aterms[!stylest2aterms %in% stylest1terms]))
temp <- c("--", "-")
term_matrix(temp)
dfm(tokens(temp))
dat$headline <- gsub("--", "-", dat$headline)
test1 <- term_matrix(dat$headline)
test2.tok <- tokens(dat$headline)
test2a <- dfm(test2.tok)
test2b.tok <- tokens(dat$headline, split_hyphens = T)
test2b <- dfm(test2b.tok)
dim(test1)
dim(test2a)
dim(test2b)
stylest1terms <- colnames(test1)
stylest2aterms <- colnames(test2a)
stylest2bterms <- colnames(test2b)
sort(unique(stylest1terms[!stylest1terms %in% stylest2aterms]))
#sort(unique(stylest1terms[!stylest1terms %in% stylest2bterms]))
sort(unique(stylest2aterms[!stylest2aterms %in% stylest1terms]))
temp <- c("#14-1508")
term_matrix(temp)
dfm(tokens(temp))
temp <- c("#hello")
term_matrix(temp)
dfm(tokens(temp))
dat$headline <- gsub("#", "", dat$headline)
test1 <- term_matrix(dat$headline)
test2.tok <- tokens(dat$headline)
test2a <- dfm(test2.tok)
test2b.tok <- tokens(dat$headline, split_hyphens = T)
test2b <- dfm(test2b.tok)
dim(test1)
dim(test2a)
dim(test2b)
stylest1terms <- colnames(test1)
stylest2aterms <- colnames(test2a)
stylest2bterms <- colnames(test2b)
sort(unique(stylest1terms[!stylest1terms %in% stylest2aterms]))
#sort(unique(stylest1terms[!stylest1terms %in% stylest2bterms]))
sort(unique(stylest2aterms[!stylest2aterms %in% stylest1terms]))
#sort(unique(stylest2bterms[!stylest2bterms %in% stylest1terms]))
temp <- c("wars'-meets-shakespeare")
term_matrix(temp)
dfm(tokens(temp))
temp <- c("-meets-shakespeare")
term_matrix(temp)
dfm(tokens(temp))
## looks like term_matrix() splits on the "'" character. Also separates "-"
## from any text that follows
temp <- c("wars'meets-shakespeare")
term_matrix(temp)
dfm(tokens(temp))
## looks like term_matrix() splits on the "'" character. Also separates "-"
## from any text that follows
temp <- c("wars'-meets-shakespeare")
term_matrix(temp)
dfm(tokens(temp))
temp <- c("wars-meets-shakespeare")
term_matrix(temp)
dfm(tokens(temp))
temp <- c("wars'-meets-shakespeare")
term_matrix(temp)
dfm(tokens(temp))
temp <- c("wars'meets-shakespeare")
term_matrix(temp)
dfm(tokens(temp))
temp <- c("-meets-shakespeare")
term_matrix(temp)
dfm(tokens(temp))
## also breaks the hyphen away from the subsequent text when it is a leading hyphen
temp <- c("-meets-shakespeare")
term_matrix(temp)
dfm(tokens(temp))
temp <- c("'-meets-shakespeare")
term_matrix(temp)
dfm(tokens(temp))
temp <- c("wars'")
term_matrix(temp)
dfm(tokens(temp))
library(quanteda)
library(corpus)
load("novels_excerpts.RData")
## both quanteda and corpus will separate text from trailing hyphens
temp <- c("wars'")
term_matrix(temp)
dfm(tokens(temp))
temp="ever-growing"
corpus::term_matrix(temp)
library(quanteda)
dfm(tokens(temp))
temp="Christian's"
corpus::term_matrix(temp)
dfm(tokens(temp))
line <- "I went to the store --but forgot my wallet"
as.matrix(corpus::term_matrix(line))
as.matrix(quanteda::dfm(tokens(line)))
as.matrix(quanteda::dfm(tokens(line, split_hyphens = T)))
dat=read.csv("/Users/christianbaehr/Desktop/scrape_municipality_catcherrors/muni_data_Allegheny_1.csv", sep = ";")
View(dat)
library(quanteda.corpora)
help("quanteda.corpora")
help("quanteda.corpora-package")
dat <- data_corpus_sotu
library(stylest)
library(quanteda)
library(quanteda.corpora)
dat <- data_corpus_sotu
dat_dfm <- dfm(dat)
rm(list = ls())
sotu <- data_corpus_sotu
sotu_dfm <- dfm(tokens(dat))
sotu <- data_corpus_sotu
sotu_dfm <- dfm(tokens(sotu))
setwd("/Users/christianbaehr/Documents/GitHub/stylest2/R/")
source("stylest2_select_vocab.R")
source("stylest2_fit.R")
source("stylest2_predict.R")
num <- sample(1:1000, 1)
set.seed(num)
num <- sample(1:1000, 1)
set.seed(num)
docvars(sotu)
s1_terms <- stylest_select_vocab(x=sotu, speaker = docvars(sotu)["President"])
s1_terms <- stylest_select_vocab(x=sotu, speaker = docvars(sotu)["President"][[1]])
s1_terms <- stylest_select_vocab(x=as.character(sotu), speaker = docvars(sotu)["President"][[1]])
s1_terms$miss_pct
set.seed(num)
s2_terms <- stylest2_select_vocab(dfm=sotu_dfm)
docvars(sotu_dfm) <- docvars(sotu)["President"][[1]]
docvars(sotu_dfm)["author"] <- docvars(sotu)["President"][[1]]
set.seed(num)
s2_terms <- stylest2_select_vocab(dfm=sotu_dfm)
s2_terms$cv_missrate_results
s1_terms$miss_pct
s2_terms$cv_missrate_results
s2_terms$cutoff_pct_best
s2_terms$cv_missrate_results
missrate_error <- as.numeric(s1_terms$miss_pct - s2_terms$cv_missrate_results)
hist(missrate_error)
hist(missrate_error, xlab = "Percentage pt. diff. in missrate")
s1_fit <- stylest_fit(x = as.character(sotu), speaker = docvars(sotu)["President"][[1]],
smooth = 0.5, terms = NULL, term_weights = NULL)
s2_fit <- stylest2_fit(dfm=sotu_dfm)
s2_fit
s2_fit$rate
colnames(s2_fit$rate)
colnames(s1_fit$rate)
colnames(s2_fit$rate)
common_cols <- unique(c(colnames(s1_fit$rate)[colnames(s1_fit$rate) %in% colnames(s2_fit$rate)],
colnames(s2_fit$rate)[colnames(s2_fit$rate) %in% colnames(s1_fit$rate)]))
rownames(s1_fit$rate)
rownames(s2_fit$rate)
s1_fit$rate <- s1_fit$rate[ , common_cols]
s2_fit$rate <- s2_fit$rate[ , common_cols]
hist(as.numeric(s1_fit$rate - s2_fit$rate))
s1_pred <- stylest_predict(model = s1_fit, text = docvars(sotu)["President"][[1]])
s1_fit <- stylest_fit(x = as.character(sotu), speaker = docvars(sotu)["President"][[1]],
smooth = 0.5, terms = NULL, term_weights = NULL)
s2_fit <- stylest2_fit(dfm=sotu_dfm)
s1_fit <- stylest_fit(x = as.character(sotu), speaker = docvars(sotu)["President"][[1]],
smooth = 0.5, terms = NULL, term_weights = NULL)
s2_fit <- stylest2_fit(dfm=sotu_dfm)
common_cols <- unique(c(colnames(s1_fit$rate)[colnames(s1_fit$rate) %in% colnames(s2_fit$rate)],
colnames(s2_fit$rate)[colnames(s2_fit$rate) %in% colnames(s1_fit$rate)]))
s1_fit_comp <- s1_fit$rate[ , common_cols] # align columns (features) for ease of comparison
s2_fit_comp <- s2_fit$rate[ , common_cols]
hist(as.numeric(s1_fit_comp - s2_fit_comp))
s1_pred <- stylest_predict(model = s1_fit, text = docvars(sotu)["President"][[1]])
s2_pred <- stylest2_predict(dfm=sotu_dfm, model = s2_fit, speaker_odds = T,
term_influence = T)
s1_pred <- stylest_predict(model = s1_fit, text = docvars(sotu)["President"][[1]])
s2_pred <- stylest2_predict(dfm=sotu_dfm, model = s2_fit, speaker_odds = T,
term_influence = T)
source("../R/stylest2_select_vocab.R")
source("../R/stylest2_fit.R")
source("../R/stylest2_predict.R")
s1_pred <- stylest_predict(model = s1_fit, text = docvars(sotu)["President"][[1]])
s2_pred <- stylest2_predict(dfm=sotu_dfm, model = s2_fit, speaker_odds = T,
term_influence = T)
s1_pred$predicted
s2_pred$posterior$predicted
s1_pred$predicted == s2_pred$posterior$predicted
sum((s1_pred$predicted == s2_pred$posterior$predicted)/length(s1_pred$predicted))
s1_pred$log_probs
s1_pred$log_probs[[1]]
s1_pred$log_probs
s1_pred$log_probs
class(s1_pred$log_probs
)
dim(s1_pred$log_probs
)
s2_pred$posterior$log_probs
as.matrix(s1_pred$log_probs)
as.matrix(s2_pred$posterior$log_probs)
sum((s1_pred$predicted == s2_pred$posterior$predicted)/length(s1_pred$predicted)) # prediction agreement rate
